{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning\n",
    "\n",
    "Here we are checking the performance of the model trained on the English Dataset on other Datasets and their translated versions without any finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import BERT\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_cleaning import Data_Preprocessing\n",
    "from arabert.preprocess import ArabertPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,isArabic):\n",
    "    \n",
    "    X = df['Text']\n",
    "    X_new=[]\n",
    "    if(isArabic):\n",
    "        prep = ArabertPreprocessor('bert-base-arabertv02')\n",
    "        for text in tqdm(X):\n",
    "            text = prep.preprocess(text)\n",
    "            X_new.append(text)\n",
    "    else:\n",
    "        processer = Data_Preprocessing()\n",
    "        for text in tqdm(X):\n",
    "            text= processer.removeEmojis(text)\n",
    "            text = processer.removeUrls(text)\n",
    "            text=processer.removeSpecialChar(text)\n",
    "            X_new.append(text)\n",
    "\n",
    "    df['Text']=X_new\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(args,data_path,index):\n",
    "    # read dataframes\n",
    "    df_test = pd.read_csv(data_path+'test_'+str(index)+'.csv')\n",
    "\n",
    "    # clean data\n",
    "    df_test=preprocess(df_test,args['isArabic'])\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_output(model_path,data_path,obj,args):\n",
    "    saved_model=obj.load_model(model_path,args)\n",
    "    device = torch.device(args['device'])\n",
    "    saved_model=saved_model.to(device)\n",
    "    \n",
    "    all_metrics={}\n",
    "    \n",
    "    # preprocessing\n",
    "    for fold in [1,2,3,4,5]:\n",
    "        df = load_dataset(args,data_path,fold)\n",
    "\n",
    "        metrics = obj.run_test(saved_model,df,args)\n",
    "        \n",
    "        for key,value in metrics.items():\n",
    "            if(key not in all_metrics):\n",
    "                all_metrics[key]=value\n",
    "            else:\n",
    "                all_metrics[key]+=value\n",
    "    \n",
    "    for key,value in all_metrics.items():\n",
    "        all_metrics[key]/=5\n",
    "    \n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/Let-Mi/\"\n",
    "MODEL_PATH = \"Saved_Models/Let-Mi/all_but_one/best_bert_bert_3_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': True,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/AMI-2020/\"\n",
    "MODEL_PATH = \"Saved_Models/AMI-2020/all_but_one/best_bert_bert_2_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': False,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_hin/\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_hin/all_but_one/best_bert_bert_1_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 4.5],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': False,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bengali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_iben/\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_iben/all_but_one/best_bert_bert_2_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 6.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': False,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/AMI-Spanish/\"\n",
    "MODEL_PATH = \"Saved_Models/AMI-Spanish/all_but_one/best_bert_bert_4_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': False,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_eng/\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_eng/all_but_one/best_bert_bert_1_all.pt\"\n",
    "\n",
    "args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 8.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'name': 'bert_one_shot',\n",
    "        'isArabic': False,\n",
    "    }\n",
    "\n",
    "model = BERT(args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Learning\n",
    "\n",
    "Here we are checking the performance of the model trained on the English Dataset on other Datasets and their translated versions with finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import random\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Tokeniser\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Scheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Optimiser\n",
    "from transformers import AdamW\n",
    "\n",
    "# Model\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_FewShot:\n",
    "    def __init__(self,args):\n",
    "        # fix the random\n",
    "        random.seed(args['seed_val'])\n",
    "        np.random.seed(args['seed_val'])\n",
    "        torch.manual_seed(args['seed_val'])\n",
    "        torch.cuda.manual_seed_all(args['seed_val'])\n",
    "        \n",
    "        # set device\n",
    "        self.device = torch.device(args['device'])\n",
    "\n",
    "        self.weights=args['weights']\n",
    "        \n",
    "        # initiliase tokeniser\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(args['bert_model'])\n",
    "\n",
    "        self.model_save_path = args['model_save_path']\n",
    "        self.name = args['name']\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Utility Functions -----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def encode(self,data,max_len):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for sent in tqdm(data):\n",
    "            # use in-built tokeniser of Bert\n",
    "            encoded_dict = self.tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens =True, # for [CLS] and [SEP]\n",
    "                            max_length = max_len,\n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt', # return pytorch tensors\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            # attention masks notify where padding has been added \n",
    "            # and where is the sentence\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "        return [input_ids,attention_masks]\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##------------------ Dataloader -----------------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def get_dataloader(self,samples, batch_size,is_train=False):\n",
    "        inputs,masks,labels = samples\n",
    "\n",
    "        # Convert the lists into tensors.\n",
    "        inputs = torch.cat(inputs, dim=0)\n",
    "        masks = torch.cat(masks, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        # convert to dataset\n",
    "        data = TensorDataset(inputs,masks,labels)\n",
    "\n",
    "        if(is_train==False):\n",
    "            # use random sampler for training to shuffle\n",
    "            # train data\n",
    "            sampler = SequentialSampler(data)\n",
    "        else:\n",
    "            # order does not matter for validation as we just \n",
    "            # need the metrics\n",
    "            sampler = RandomSampler(data)  \n",
    "\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size,drop_last=True)\n",
    "\n",
    "        return dataloader\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Training Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def get_optimiser(self,learning_rate,model):\n",
    "        # using AdamW optimiser from transformers library\n",
    "        return AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "    def get_scheduler(self,epochs,optimiser,train_dl):\n",
    "        total_steps = len(train_dl) * epochs\n",
    "        return get_linear_schedule_with_warmup(optimiser, \n",
    "                num_warmup_steps = 0, \n",
    "                num_training_steps = total_steps)\n",
    "    \n",
    "    def evalMetric(self, y_true, y_pred, prefix):\n",
    "        # calculate all the metrics and add prefix to them\n",
    "        # before saving in dictionary\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        mf1Score = f1_score(y_true, y_pred, average='macro')\n",
    "        f1Score = f1_score(y_true, y_pred)\n",
    "        area_under_c = roc_auc_score(y_true, y_pred)\n",
    "        recallScore = recall_score(y_true, y_pred)\n",
    "        precisionScore = precision_score(y_true, y_pred)\n",
    "\n",
    "        nonhate_f1Score = f1_score(y_true, y_pred, pos_label=0)\n",
    "        non_recallScore = recall_score(y_true, y_pred, pos_label=0)\n",
    "        non_precisionScore = precision_score(y_true, y_pred, pos_label=0)\n",
    "        return {prefix+\"accuracy\": accuracy, prefix+'mF1Score': mf1Score, \n",
    "            prefix+'f1Score': f1Score, prefix+'auc': area_under_c,\n",
    "            prefix+'precision': precisionScore, \n",
    "            prefix+'recall': recallScore, \n",
    "            prefix+'non_hatef1Score': nonhate_f1Score, \n",
    "            prefix+'non_recallScore': non_recallScore, \n",
    "            prefix+'non_precisionScore': non_precisionScore}\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##---------------- Different Train Loops --------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def evaluate(self,model,loader,which):\n",
    "        # to evaluate model on test and validation set\n",
    "\n",
    "        model.eval() # put model in eval mode\n",
    "\n",
    "        # maintain total loss to save in metrics\n",
    "        total_eval_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(loader):\n",
    "            # separate input, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            with torch.no_grad(): # do not construct compute graph\n",
    "                outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "            # output is always a tuple, thus we have to \n",
    "            # separate it manually\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "\n",
    "            # add the current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # calculate true labels and convert it into numpy array\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "            \n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "        # calculate metrics\n",
    "        metrics = self.evalMetric(y_true,y_pred,which+\"_\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_loss = total_eval_loss / len(loader)\n",
    "        # add it to the metric\n",
    "        metrics[which+'_avg_loss'] = avg_loss\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    def run_train_loop(self,model,train_loader,optimiser,scheduler):\n",
    "\n",
    "        model.train() # put model in train mode\n",
    "\n",
    "        # maintain total loss to add to metric\n",
    "        total_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            # separate inputs, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            # Ref: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch#:~:text=In%20PyTorch%20%2C%20we%20need%20to,backward()%20call.\n",
    "            model.zero_grad()                \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "            # outputs is always returned as tuple\n",
    "            # Separate it manually\n",
    "            logits = outputs[1]\n",
    "\n",
    "            # define new loss function so that we can include\n",
    "            # weights\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float)).to(self.device)\n",
    "            \n",
    "            loss = loss_fct(logits,b_labels)\n",
    "            \n",
    "            # calculate current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # calculate true labels\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "\n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "            # clip gradient to prevent exploding gradient\n",
    "            # problems\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # gradient descent\n",
    "            optimiser.step()\n",
    "            \n",
    "            # schedule learning rate accordingly\n",
    "            scheduler.step()\n",
    "\n",
    "        # calculate avg loss \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # calculate metrics\n",
    "        train_metrics = self.evalMetric(y_true,y_pred,\"Train_\")\n",
    "        \n",
    "        # print results\n",
    "        print('avg_train_loss',avg_train_loss)\n",
    "        print('train_f1Score',train_metrics['Train_f1Score'])\n",
    "        print('train_accuracy',train_metrics['Train_accuracy'])\n",
    "\n",
    "        # add loss to metrics\n",
    "        train_metrics['Train_avg_loss'] = avg_train_loss\n",
    "\n",
    "        return train_metrics\n",
    "    \n",
    "    \n",
    "    ##------------------------------------------------------------##\n",
    "    ##----------------- Main Train Loop --------------------------##\n",
    "    ##------------------------------------------------------------##\n",
    "    def train(self,model,data_loaders,optimiser,scheduler,epochs,save_model):\n",
    "        # save train stats per epoch\n",
    "        train_stats = []\n",
    "        test_stats=[]\n",
    "        best_test={}\n",
    "        train_loader,val_loader,test_loader = data_loaders\n",
    "        # maintain best mF1 Score to save best model\n",
    "        best_mf1Score=-1.0\n",
    "        for epoch_i in range(0, epochs):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            \n",
    "            print(\"\")\n",
    "            print('Training...')\n",
    "            # run trian loop\n",
    "            train_metrics = self.run_train_loop(model,train_loader,\n",
    "                                            optimiser,scheduler)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\") \n",
    "            # test on validation set\n",
    "            val_metrics = self.evaluate(model,val_loader,\"Val\")\n",
    "            \n",
    "            print(\"Validation Loss: \",val_metrics['Val_avg_loss'])\n",
    "            print(\"Validation Accuracy: \",val_metrics['Val_accuracy'])\n",
    "            \n",
    "            stats = {}\n",
    "            \n",
    "            if(val_metrics['Val_mF1Score']>best_mf1Score):\n",
    "                print(\"Best mF1Score....\")\n",
    "                best_mf1Score=val_metrics['Val_mF1Score']\n",
    "                if(save_model):\n",
    "                    torch.save(model.state_dict(), self.model_save_path+\n",
    "                        '/best_bert_'+self.name+'.pt')\n",
    "                # evaluate model on test set\n",
    "                best_test = self.evaluate(model,test_loader,'')\n",
    "                best_test['name']=self.name+'_'+str(epoch_i)+'_best'\n",
    "\n",
    "\n",
    "            stats['epoch']=epoch_i+1\n",
    "\n",
    "            # add train and val metrics of the epoch to \n",
    "            # same dictionary\n",
    "            stats.update(train_metrics)\n",
    "            stats.update(val_metrics)\n",
    "\n",
    "            train_stats.append(stats)\n",
    "            \n",
    "        test_stats.append(best_test)\n",
    "        return train_stats,best_test\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------------- Main Pipeline ---------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run(self,args,df_train,df_val,df_test):\n",
    "        # get X and Y data points \n",
    "        X_train = df_train['Text'].values\n",
    "        Y_train = df_train['Label'].values\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "        X_val = df_val['Text'].values\n",
    "        Y_val = df_val['Label'].values\n",
    "        \n",
    "        # encode data\n",
    "        # returns list of data and attention masks\n",
    "        train_data = self.encode(X_train,args['max_len'])\n",
    "        val_data = self.encode(X_val,args['max_len'])\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "        \n",
    "        # add labels to data so that we can send them to\n",
    "        # dataloader function together\n",
    "        train_data.append(Y_train)\n",
    "        val_data.append(Y_val)\n",
    "        test_data.append(Y_test)\n",
    "        \n",
    "        # convert to dataloader\n",
    "        train_dl =self.get_dataloader(train_data,args['batch_size'],True)\n",
    "        val_dl =self.get_dataloader(val_data,args['batch_size'])                          \n",
    "        test_dl =self.get_dataloader(test_data,args['batch_size'])\n",
    "        \n",
    "        # intialise model\n",
    "#         model = BertForSequenceClassification.from_pretrained(\n",
    "#                 args['bert_model'], \n",
    "#                 num_labels = 2, \n",
    "#                 output_attentions = False, # Whether the model returns attentions weights.\n",
    "#                 output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "#             )\n",
    "        model = self.load_model(args['model_path'],args)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        optimiser = self.get_optimiser(args['learning_rate'],model)\n",
    "        \n",
    "        scheduler = self.get_scheduler(args['epochs'],optimiser,train_dl)\n",
    "        \n",
    "        # Run train loop and evaluate on validation data set\n",
    "        # on each epoch. Store best model from all epochs \n",
    "        # (best mF1 Score on Val set) and evaluate it on\n",
    "        # test set\n",
    "        train_stats,best_test = self.train(model,[train_dl,val_dl,test_dl],\n",
    "                                optimiser,scheduler,args['epochs'],args['save_model'])\n",
    "        \n",
    "        return train_stats,best_test\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##-------------------- Other Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run_test(self,model,df_test,args):\n",
    "        # to evaluate test set on the final saved model\n",
    "        # to retrieve results if necessary\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "\n",
    "        test_data.append(Y_test)\n",
    "\n",
    "        test_dl =self.get_dataloader(test_data,32)\n",
    "\n",
    "        metrics = self.evaluate(model,test_dl,\"Test\")\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def load_model(self,path,args):\n",
    "        # load saved best model\n",
    "        saved_model = BertForSequenceClassification.from_pretrained(\n",
    "                args['bert_model'], \n",
    "                num_labels = 2, \n",
    "                output_attentions = False, # Whether the model returns attentions weights.\n",
    "                output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "            )\n",
    "        \n",
    "        saved_model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        return saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(args,index):\n",
    "    # initialise constants \n",
    "    path = args['data_path']\n",
    "    # read dataframes\n",
    "    df_train = pd.read_csv(path+'train_'+str(index)+'.csv')\n",
    "    df_val = pd.read_csv(path+'val_'+str(index)+'.csv')\n",
    "    df_test = pd.read_csv(path+'test_'+str(index)+'.csv')\n",
    "\n",
    "    # clean data\n",
    "    df_train=preprocess(df_train,args['isArabic'])\n",
    "    df_val=preprocess(df_val,args['isArabic'])\n",
    "    df_test=preprocess(df_test,args['isArabic'])\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,isArabic):\n",
    "    \n",
    "    X = df['Text']\n",
    "    X_new=[]\n",
    "    if(isArabic):\n",
    "        prep = ArabertPreprocessor('bert-base-arabertv02')\n",
    "        for text in tqdm(X):\n",
    "            text = prep.preprocess(text)\n",
    "            X_new.append(text)\n",
    "    else:\n",
    "        processer = Data_Preprocessing()\n",
    "        for text in tqdm(X):\n",
    "            text= processer.removeEmojis(text)\n",
    "            text = processer.removeUrls(text)\n",
    "            text=processer.removeSpecialChar(text)\n",
    "            X_new.append(text)\n",
    "\n",
    "    df['Text']=X_new\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(path,metrics,which):\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(path+\"_\"+which+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, index,all_test_metrics,model_args):\n",
    "    model_name = args['model_name']\n",
    "    model_args['name']=model_name+'_'+str(index)+'_all'\n",
    "    print(\"\\tInitialising Model....\")\n",
    "    model = BERT_FewShot(model_args)\n",
    "    print(\"\\tLoading Dataset....\")\n",
    "    df_train, df_val, df_test = load_dataset(args,index)\n",
    "    print(\"\\tTraining Starts....\")\n",
    "    train_metrics, test_metrics = model.run(model_args, \n",
    "                    df_train, df_val, df_test)\n",
    "\n",
    "    # Save train metrics after generating path\n",
    "    res_path=args['res_base_path']+model_name+'_'+model_args['name']\n",
    "    save_metrics(res_path,train_metrics,\"train\")\n",
    "    \n",
    "    all_test_metrics.append(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args,model_args):\n",
    "    all_test_metrics=[]\n",
    "    \n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"Fold: \",fold)\n",
    "        fix_random()\n",
    "        train(args,fold,all_test_metrics,model_args)\n",
    "        print(\"Saving Test Metrics....\")\n",
    "        save_metrics(args['res_base_path']+args['model_name']+\n",
    "             '_all',all_test_metrics,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Let-Mi/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Let-Mi/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Let-Mi/',\n",
    "    'isArabic': True,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': True,\n",
    "        'model_path': \"Saved_Models/Let-Mi/all_but_one/best_bert_bert_3_all.pt\",\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/AMI-Spanish/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/AMI-Spanish/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/AMI-Spanish/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_hin/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_hin/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_hin/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 4.5],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less data points few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_part(train_cnt,args,index,seed):\n",
    "    # initialise constants \n",
    "    path = args['data_path']\n",
    "    # read dataframes\n",
    "    df_train = pd.read_csv(path+'train_'+str(index)+'.csv')\n",
    "    df_val = pd.read_csv(path+'val_'+str(index)+'.csv')\n",
    "    df_test = pd.read_csv(path+'test_'+str(index)+'.csv')\n",
    "    \n",
    "    # split train into hate and non-hate and take train_cnt\n",
    "    # samples of each\n",
    "    df_train_hate = df_train[df_train['Label'] == 1].sample(train_cnt,random_state=seed)\n",
    "    df_train_non_hate = df_train[df_train['Label'] == 0].sample(train_cnt,random_state=seed)\n",
    "    # concatenate hate and non_hate\n",
    "    df_train = pd.concat([df_train_hate, df_train_non_hate])\n",
    "    # shuffle the train data\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # clean data\n",
    "    df_train=preprocess(df_train,args['isArabic'])\n",
    "    df_val=preprocess(df_val,args['isArabic'])\n",
    "    df_test=preprocess(df_test,args['isArabic'])\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part(args,train_cnt,run,index,all_test_metrics,model_args,seed):\n",
    "    model_name = args['model_name']\n",
    "    model_args['name']=model_name+'_'+str(index)+'_'+str(train_cnt)+'_'+str(run)\n",
    "    print(\"\\tInitialising Model....\")\n",
    "    model = BERT_FewShot(model_args)\n",
    "    print(\"\\tLoading Dataset....\")\n",
    "    df_train, df_val, df_test = load_dataset_part(train_cnt,args,index,seed)\n",
    "    print(\"\\tTraining Starts....\")\n",
    "    train_metrics, test_metrics = model.run(model_args, \n",
    "                    df_train, df_val, df_test)\n",
    "\n",
    "    # Save train metrics after generating path\n",
    "    res_path=args['res_base_path']+model_name+'_'+model_args['name']\n",
    "    save_metrics(res_path,train_metrics,\"train\")\n",
    "    \n",
    "    all_test_metrics.append(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_part(run_args,model_args,train_cnt):\n",
    "    all_test_metrics=[]\n",
    "    seeds = [42,43,44]\n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"Fold: \",fold)\n",
    "        for run in [1,2,3]:\n",
    "            print(\"Run: \",run)\n",
    "            fix_random()\n",
    "            train_part(run_args,train_cnt,run,fold,all_test_metrics,model_args,seeds[run-1])\n",
    "            print(\"Saving Test Metrics....\")\n",
    "            save_metrics(run_args['res_base_path']+run_args['model_name']+\n",
    "             '_'+str(train_cnt),all_test_metrics,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic few data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Let-Mi/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Let-Mi/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Let-Mi/',\n",
    "    'isArabic': True,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': True,\n",
    "        'model_path': \"Saved_Models/Let-Mi/all_but_one/best_bert_bert_3_all.pt\",\n",
    "    }\n",
    "for train_cnt in [512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Italian few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/AMI-2020/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/AMI-2020/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/AMI-2020/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/AMI-2020/all_but_one/best_bert_bert_1_all.pt\",\n",
    "    }\n",
    "for train_cnt in [64,128,256,512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/AMI-Spanish/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/AMI-Spanish/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/AMI-Spanish/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/AMI-Spanish/all_but_one/best_bert_bert_4_all.pt\",\n",
    "    }\n",
    "for train_cnt in [128,256,512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_hin/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_hin/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_hin/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_hin/all_but_one/best_bert_bert_1_all.pt\",\n",
    "    }\n",
    "for train_cnt in [512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bengali Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_iben/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_iben/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_iben/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_iben/all_but_one/best_bert_bert_2_all.pt\",\n",
    "    }\n",
    "for train_cnt in [32,64,128,256,512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_eng/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_eng/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_eng/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng/all_but_one/best_bert_bert_1_all.pt\",\n",
    "    }\n",
    "for train_cnt in [32,64,128,256,512]:\n",
    "    print(\"Train Cnt: \",train_cnt)\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
