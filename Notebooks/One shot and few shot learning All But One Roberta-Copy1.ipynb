{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning\n",
    "\n",
    "Here we are checking the performance of the model trained on the English Dataset on other Datasets and their translated versions without any finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_cleaning import Data_Preprocessing\n",
    "from arabert.preprocess import ArabertPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import random\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Tokeniser\n",
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "# Utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Scheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Optimiser\n",
    "from transformers import AdamW\n",
    "\n",
    "# Model\n",
    "\n",
    "import torch.nn as nn\n",
    "from models import weighted_Roberta\n",
    "\n",
    "\n",
    "class XLM_Roberta:\n",
    "    def __init__(self,args):\n",
    "        # fix the random\n",
    "        random.seed(args['seed_val'])\n",
    "        np.random.seed(args['seed_val'])\n",
    "        torch.manual_seed(args['seed_val'])\n",
    "        torch.cuda.manual_seed_all(args['seed_val'])\n",
    "        \n",
    "        # set device\n",
    "        self.device = torch.device(args['device'])\n",
    "\n",
    "        self.weights=args['weights']\n",
    "        \n",
    "        # initiliase tokeniser\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case = True)\n",
    "\n",
    "        self.model_save_path = args['model_save_path']\n",
    "        self.name = args['name']\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Utility Functions -----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def encode(self,data,max_len):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for sent in tqdm(data):\n",
    "            # use in-built tokeniser of Bert\n",
    "            encoded_dict = self.tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens =True, # for [CLS] and [SEP]\n",
    "                            max_length = max_len,\n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,\n",
    "#                             return_tensors = 'pt', # return pytorch tensors\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            # attention masks notify where padding has been added \n",
    "            # and where is the sentence\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            X_data = torch.tensor(input_ids)\n",
    "            attention_masks_data = torch.tensor(attention_masks)\n",
    "            \n",
    "        return [X_data,attention_masks_data]\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##------------------ Dataloader -----------------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def get_dataloader(self,samples, batch_size,is_train=False):\n",
    "        inputs,masks,labels = samples\n",
    "\n",
    "        # Convert the lists into tensors.\n",
    "#         inputs = torch.cat(inputs, dim=0)\n",
    "#         masks = torch.cat(masks, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        # convert to dataset\n",
    "        data = TensorDataset(inputs,masks,labels)\n",
    "\n",
    "        if(is_train==False):\n",
    "            # use random sampler for training to shuffle\n",
    "            # train data\n",
    "            sampler = SequentialSampler(data)\n",
    "        else:\n",
    "            # order does not matter for validation as we just \n",
    "            # need the metrics\n",
    "            sampler = RandomSampler(data)  \n",
    "\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size,drop_last=True)\n",
    "\n",
    "        return dataloader\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Training Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def get_optimiser(self,learning_rate,model):\n",
    "        # using AdamW optimiser from transformers library\n",
    "        return AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "    def get_scheduler(self,epochs,optimiser,train_dl):\n",
    "        total_steps = len(train_dl) * epochs\n",
    "        return get_linear_schedule_with_warmup(optimiser, \n",
    "                num_warmup_steps = 0, \n",
    "                num_training_steps = total_steps)\n",
    "    \n",
    "    def evalMetric(self, y_true, y_pred, prefix):\n",
    "        # calculate all the metrics and add prefix to them\n",
    "        # before saving in dictionary\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        mf1Score = f1_score(y_true, y_pred, average='macro')\n",
    "        f1Score = f1_score(y_true, y_pred)\n",
    "        area_under_c = roc_auc_score(y_true, y_pred)\n",
    "        recallScore = recall_score(y_true, y_pred)\n",
    "        precisionScore = precision_score(y_true, y_pred)\n",
    "\n",
    "        nonhate_f1Score = f1_score(y_true, y_pred, pos_label=0)\n",
    "        non_recallScore = recall_score(y_true, y_pred, pos_label=0)\n",
    "        non_precisionScore = precision_score(y_true, y_pred, pos_label=0)\n",
    "        return {prefix+\"accuracy\": accuracy, prefix+'mF1Score': mf1Score, \n",
    "            prefix+'f1Score': f1Score, prefix+'auc': area_under_c,\n",
    "            prefix+'precision': precisionScore, \n",
    "            prefix+'recall': recallScore, \n",
    "            prefix+'non_hatef1Score': nonhate_f1Score, \n",
    "            prefix+'non_recallScore': non_recallScore, \n",
    "            prefix+'non_precisionScore': non_precisionScore}\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##---------------- Different Train Loops --------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def evaluate(self,model,loader,which):\n",
    "        # to evaluate model on test and validation set\n",
    "\n",
    "        model.eval() # put model in eval mode\n",
    "\n",
    "        # maintain total loss to save in metrics\n",
    "        total_eval_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(loader):\n",
    "            # separate input, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            with torch.no_grad(): # do not construct compute graph\n",
    "                outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "            # output is always a tuple, thus we have to \n",
    "            # separate it manually\n",
    "            #loss = outputs[0]\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # define new loss function so that we can include\n",
    "            # weights\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float).to(self.device))\n",
    "            \n",
    "            loss = loss_fct(logits.view(-1, 2), b_labels.view(-1))\n",
    "\n",
    "            # add the current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # calculate true labels and convert it into numpy array\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "            \n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "        # calculate metrics\n",
    "        metrics = self.evalMetric(y_true,y_pred,which+\"_\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_loss = total_eval_loss / len(loader)\n",
    "        # add it to the metric\n",
    "        metrics[which+'_avg_loss'] = avg_loss\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    def run_train_loop(self,model,train_loader,optimiser,scheduler):\n",
    "\n",
    "        model.train() # put model in train mode\n",
    "\n",
    "        # maintain total loss to add to metric\n",
    "        total_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            # separate inputs, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            # Ref: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch#:~:text=In%20PyTorch%20%2C%20we%20need%20to,backward()%20call.\n",
    "            model.zero_grad()                \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "            # outputs is always returned as tuple\n",
    "            # Separate it manually\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # define new loss function so that we can include\n",
    "            # weights\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float).to(self.device))\n",
    "            \n",
    "            loss = loss_fct(logits.view(-1, 2), b_labels.view(-1))\n",
    "            \n",
    "            # calculate current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # calculate true labels\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "\n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "            # clip gradient to prevent exploding gradient\n",
    "            # problems\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # gradient descent\n",
    "            optimiser.step()\n",
    "            \n",
    "            # schedule learning rate accordingly\n",
    "            scheduler.step()\n",
    "\n",
    "        # calculate avg loss \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # calculate metrics\n",
    "        train_metrics = self.evalMetric(y_true,y_pred,\"Train_\")\n",
    "        \n",
    "        # print results\n",
    "        print('avg_train_loss',avg_train_loss)\n",
    "        print('train_f1Score',train_metrics['Train_f1Score'])\n",
    "        print('train_accuracy',train_metrics['Train_accuracy'])\n",
    "\n",
    "        # add loss to metrics\n",
    "        train_metrics['Train_avg_loss'] = avg_train_loss\n",
    "\n",
    "        return train_metrics\n",
    "    \n",
    "    \n",
    "    ##------------------------------------------------------------##\n",
    "    ##----------------- Main Train Loop --------------------------##\n",
    "    ##------------------------------------------------------------##\n",
    "    def train(self,model,data_loaders,optimiser,scheduler,epochs,save_model):\n",
    "        # save train stats per epoch\n",
    "        train_stats = []\n",
    "        train_loader,val_loader,test_loader = data_loaders\n",
    "        # maintain best mF1 Score to save best model\n",
    "        best_mf1Score=-1.0\n",
    "        for epoch_i in range(0, epochs):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            \n",
    "            print(\"\")\n",
    "            print('Training...')\n",
    "            # run trian loop\n",
    "            train_metrics = self.run_train_loop(model,train_loader,\n",
    "                                            optimiser,scheduler)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\") \n",
    "            # test on validation set\n",
    "            val_metrics = self.evaluate(model,val_loader,\"Val\")\n",
    "            \n",
    "            print(\"Validation Loss: \",val_metrics['Val_avg_loss'])\n",
    "            print(\"Validation Accuracy: \",val_metrics['Val_accuracy'])\n",
    "            \n",
    "            stats = {}\n",
    "\n",
    "            # save model where validation mF1Score is best\n",
    "            if(val_metrics['Val_mF1Score']>best_mf1Score):\n",
    "                best_mf1Score=val_metrics['Val_mF1Score']\n",
    "                if(save_model):\n",
    "                    torch.save(model.state_dict(), self.model_save_path+\n",
    "                        '/best_bert_'+self.name+'.pt')\n",
    "                # evaluate best model on test set\n",
    "                test_metrics = self.evaluate(model,test_loader,\"Test\")\n",
    "\n",
    "            stats['epoch']=epoch_i+1\n",
    "\n",
    "            # add train and val metrics of the epoch to \n",
    "            # same dictionary\n",
    "            stats.update(train_metrics)\n",
    "            stats.update(val_metrics)\n",
    "\n",
    "            train_stats.append(stats)\n",
    "\n",
    "        return train_stats,test_metrics\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------------- Main Pipeline ---------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run(self,args,df_train,df_val,df_test):\n",
    "        # get X and Y data points \n",
    "        X_train = df_train['Text'].values\n",
    "        Y_train = df_train['Label'].values\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "        X_val = df_val['Text'].values\n",
    "        Y_val = df_val['Label'].values\n",
    "        \n",
    "        # encode data\n",
    "        # returns list of data and attention masks\n",
    "        train_data = self.encode(X_train,args['max_len'])\n",
    "        val_data = self.encode(X_val,args['max_len'])\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "        \n",
    "        # add labels to data so that we can send them to\n",
    "        # dataloader function together\n",
    "        train_data.append(Y_train)\n",
    "        val_data.append(Y_val)\n",
    "        test_data.append(Y_test)\n",
    "        \n",
    "        # convert to dataloader\n",
    "        train_dl =self.get_dataloader(train_data,args['batch_size'],True)\n",
    "        val_dl =self.get_dataloader(val_data,args['batch_size'])                          \n",
    "        test_dl =self.get_dataloader(test_data,args['batch_size'])\n",
    "        \n",
    "        # intialise model\n",
    "        model = weighted_Roberta.from_pretrained(\n",
    "            'xlm-roberta-base', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "            num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.   \n",
    "            params=args['params'],\n",
    "        )\n",
    "        model.to(self.device)\n",
    "        \n",
    "        optimiser = self.get_optimiser(args['learning_rate'],model)\n",
    "        \n",
    "        scheduler = self.get_scheduler(args['epochs'],optimiser,train_dl)\n",
    "        \n",
    "        # Run train loop and evaluate on validation data set\n",
    "        # on each epoch. Store best model from all epochs \n",
    "        # (best mF1 Score on Val set) and evaluate it on\n",
    "        # test set\n",
    "        train_stats,train_metrics = self.train(model,[train_dl,val_dl,test_dl],\n",
    "                                optimiser,scheduler,args['epochs'],args['save_model'])\n",
    "        \n",
    "        return train_stats,train_metrics\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##-------------------- Other Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run_test(self,model,df_test,args):\n",
    "        # to evaluate test set on the final saved model\n",
    "        # to retrieve results if necessary\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "\n",
    "        test_data.append(Y_test)\n",
    "\n",
    "        test_dl =self.get_dataloader(test_data,32)\n",
    "\n",
    "        metrics = self.evaluate(model,test_dl,\"Test\")\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def load_model(self,path,args):\n",
    "        # load saved best model\n",
    "        saved_model = weighted_Roberta.from_pretrained(\n",
    "            'xlm-roberta-base', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "            num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.   \n",
    "            params=args['params'],\n",
    "        )\n",
    "        \n",
    "        saved_model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        return saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,isArabic):\n",
    "    \n",
    "    X = df['Text']\n",
    "    X_new=[]\n",
    "    if(isArabic):\n",
    "        prep = ArabertPreprocessor('bert-base-arabertv02')\n",
    "        for text in tqdm(X):\n",
    "            text = prep.preprocess(text)\n",
    "            X_new.append(text)\n",
    "    else:\n",
    "        processer = Data_Preprocessing()\n",
    "        for text in tqdm(X):\n",
    "            text= processer.removeEmojis(text)\n",
    "            text = processer.removeUrls(text)\n",
    "            text=processer.removeSpecialChar(text)\n",
    "            X_new.append(text)\n",
    "\n",
    "    df['Text']=X_new\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_output(model_path,data_path,obj,args):\n",
    "    saved_model=obj.load_model(model_path,args)\n",
    "    device = torch.device(args['device'])\n",
    "    saved_model=saved_model.to(device)\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # preprocessing\n",
    "    df = preprocess(df,args['isArabic'])\n",
    "    \n",
    "    metrics = obj.run_test(saved_model,df,args)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 5240/5240 [00:00<00:00, 6079.32it/s]\n",
      "100%|██████████| 5240/5240 [03:32<00:00, 24.69it/s]\n",
      "100%|██████████| 163/163 [00:26<00:00,  6.25it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/Let-Mi/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/Let-Mi/all_but_one/best_bert_xlm_roberta_3_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': True,\n",
    "        'model_save_path': 'Saved_Models/Let-Mi/all_but_one/',\n",
    "        'isArabic': True,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.6278757668711656,\n",
       " 'Test_mF1Score': 0.6103902191176347,\n",
       " 'Test_f1Score': 0.527852104110922,\n",
       " 'Test_auc': 0.6251453031194015,\n",
       " 'Test_precision': 0.7054616384915474,\n",
       " 'Test_recall': 0.42168674698795183,\n",
       " 'Test_non_hatef1Score': 0.6929283341243474,\n",
       " 'Test_non_recallScore': 0.8286038592508513,\n",
       " 'Test_non_precisionScore': 0.5954323001631321,\n",
       " 'Test_avg_loss': 2.7577537766263527}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 9922/9922 [00:04<00:00, 1995.59it/s]\n",
      "100%|██████████| 9922/9922 [13:45<00:00, 12.02it/s] \n",
      "100%|██████████| 310/310 [01:04<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/AMI-2020/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/AMI-2020/all_but_one/best_bert_xlm_roberta_2_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': True,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.5432459677419355,\n",
       " 'Test_mF1Score': 0.5355248490400887,\n",
       " 'Test_f1Score': 0.475639393588705,\n",
       " 'Test_auc': 0.5395916489383066,\n",
       " 'Test_precision': 0.5345993756503642,\n",
       " 'Test_recall': 0.4283927454659162,\n",
       " 'Test_non_hatef1Score': 0.5954103044914724,\n",
       " 'Test_non_recallScore': 0.6507905524106968,\n",
       " 'Test_non_precisionScore': 0.5487162606978275,\n",
       " 'Test_avg_loss': 2.45584655346409}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 6181/6181 [00:02<00:00, 2352.80it/s]\n",
      "100%|██████████| 6181/6181 [03:09<00:00, 32.60it/s] \n",
      "100%|██████████| 193/193 [00:24<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_hin/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_hin/all_but_one/best_bert_xlm_roberta_1_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 4.5],\n",
    "        'save_model': True,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,4.5],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.8110427461139896,\n",
       " 'Test_mF1Score': 0.7074607574491267,\n",
       " 'Test_f1Score': 0.5333866453418632,\n",
       " 'Test_auc': 0.6947429134081914,\n",
       " 'Test_precision': 0.5923623445825933,\n",
       " 'Test_recall': 0.4850909090909091,\n",
       " 'Test_non_hatef1Score': 0.8815348695563903,\n",
       " 'Test_non_recallScore': 0.9043949177254739,\n",
       " 'Test_non_precisionScore': 0.8598019801980198,\n",
       " 'Test_avg_loss': 1.4547508923346515}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bengali "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 5971/5971 [00:01<00:00, 3649.46it/s]\n",
      "100%|██████████| 5971/5971 [03:07<00:00, 31.91it/s] \n",
      "100%|██████████| 186/186 [00:23<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_iben/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_iben/all_but_one/best_bert_xlm_roberta_5_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 6.0],\n",
    "        'save_model': True,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,6.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.8220766129032258,\n",
       " 'Test_mF1Score': 0.6104474913839375,\n",
       " 'Test_f1Score': 0.3233226837060703,\n",
       " 'Test_auc': 0.5931262235258643,\n",
       " 'Test_precision': 0.55,\n",
       " 'Test_recall': 0.22895927601809954,\n",
       " 'Test_non_hatef1Score': 0.8975722990618048,\n",
       " 'Test_non_recallScore': 0.9572931710336291,\n",
       " 'Test_non_precisionScore': 0.8448652585579024,\n",
       " 'Test_avg_loss': 1.9111749583915356}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3307/3307 [00:01<00:00, 2127.41it/s]\n",
      "100%|██████████| 3307/3307 [00:55<00:00, 60.01it/s] \n",
      "100%|██████████| 103/103 [00:13<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/AMI-Spanish/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/AMI-Spanish/all_but_one/best_bert_xlm_roberta_1_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': True,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.6119538834951457,\n",
       " 'Test_mF1Score': 0.6046830179878536,\n",
       " 'Test_f1Score': 0.551070551070551,\n",
       " 'Test_auc': 0.6111534558458562,\n",
       " 'Test_precision': 0.64822460776218,\n",
       " 'Test_recall': 0.47924297924297926,\n",
       " 'Test_non_hatef1Score': 0.6582954849051562,\n",
       " 'Test_non_recallScore': 0.7430639324487334,\n",
       " 'Test_non_precisionScore': 0.5908872901678657,\n",
       " 'Test_avg_loss': 1.2461398206289531}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 16335/16335 [00:15<00:00, 1080.88it/s]\n",
      "100%|██████████| 16335/16335 [23:20<00:00, 11.66it/s]\n",
      "100%|██████████| 510/510 [01:05<00:00,  7.84it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"Data_Processed/Shared_Task_eng/all.csv\"\n",
    "MODEL_PATH = \"Saved_Models/Shared_Task_eng/all_but_one/best_bert_xlm_roberta_4_all.pt\"\n",
    "\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 8.0],\n",
    "        'save_model': True,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"\",\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,8.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "model = XLM_Roberta(model_args)\n",
    "\n",
    "metrics = one_shot_output(MODEL_PATH,DATA_PATH,model,model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test_accuracy': 0.8345588235294118,\n",
       " 'Test_mF1Score': 0.648073605520414,\n",
       " 'Test_f1Score': 0.39189189189189194,\n",
       " 'Test_auc': 0.6264972844101598,\n",
       " 'Test_precision': 0.5367057371992597,\n",
       " 'Test_recall': 0.3086200780418588,\n",
       " 'Test_non_hatef1Score': 0.9042553191489361,\n",
       " 'Test_non_recallScore': 0.9443744907784608,\n",
       " 'Test_non_precisionScore': 0.8674059459827199,\n",
       " 'Test_avg_loss': 1.5595395457109107}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Learning\n",
    "\n",
    "Here we are checking the performance of the model trained on the English Dataset on other Datasets and their translated versions with finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLM RoBERTa Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import random\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Tokeniser\n",
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "# Utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Scheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Optimiser\n",
    "from transformers import AdamW\n",
    "\n",
    "# Model\n",
    "\n",
    "import torch.nn as nn\n",
    "from models import weighted_Roberta\n",
    "\n",
    "\n",
    "class XLM_Roberta_fewShot:\n",
    "    def __init__(self,args):\n",
    "        # fix the random\n",
    "        random.seed(args['seed_val'])\n",
    "        np.random.seed(args['seed_val'])\n",
    "        torch.manual_seed(args['seed_val'])\n",
    "        torch.cuda.manual_seed_all(args['seed_val'])\n",
    "        \n",
    "        # set device\n",
    "        self.device = torch.device(args['device'])\n",
    "\n",
    "        self.weights=args['weights']\n",
    "        \n",
    "        # initiliase tokeniser\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case = True)\n",
    "\n",
    "        self.model_save_path = args['model_save_path']\n",
    "        self.name = args['name']\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Utility Functions -----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def encode(self,data,max_len):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for sent in tqdm(data):\n",
    "            # use in-built tokeniser of Bert\n",
    "            encoded_dict = self.tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens =True, # for [CLS] and [SEP]\n",
    "                            max_length = max_len,\n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,\n",
    "#                             return_tensors = 'pt', # return pytorch tensors\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            # attention masks notify where padding has been added \n",
    "            # and where is the sentence\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "            X_data = torch.tensor(input_ids)\n",
    "            attention_masks_data = torch.tensor(attention_masks)\n",
    "            \n",
    "        return [X_data,attention_masks_data]\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##------------------ Dataloader -----------------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def get_dataloader(self,samples, batch_size,is_train=False):\n",
    "        inputs,masks,labels = samples\n",
    "\n",
    "        # Convert the lists into tensors.\n",
    "#         inputs = torch.cat(inputs, dim=0)\n",
    "#         masks = torch.cat(masks, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        # convert to dataset\n",
    "        data = TensorDataset(inputs,masks,labels)\n",
    "\n",
    "        if(is_train==False):\n",
    "            # use random sampler for training to shuffle\n",
    "            # train data\n",
    "            sampler = SequentialSampler(data)\n",
    "        else:\n",
    "            # order does not matter for validation as we just \n",
    "            # need the metrics\n",
    "            sampler = RandomSampler(data)  \n",
    "\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size,drop_last=True)\n",
    "\n",
    "        return dataloader\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Training Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def get_optimiser(self,learning_rate,model):\n",
    "        # using AdamW optimiser from transformers library\n",
    "        return AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "    def get_scheduler(self,epochs,optimiser,train_dl):\n",
    "        total_steps = len(train_dl) * epochs\n",
    "        return get_linear_schedule_with_warmup(optimiser, \n",
    "                num_warmup_steps = 0, \n",
    "                num_training_steps = total_steps)\n",
    "    \n",
    "    def evalMetric(self, y_true, y_pred, prefix):\n",
    "        # calculate all the metrics and add prefix to them\n",
    "        # before saving in dictionary\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        mf1Score = f1_score(y_true, y_pred, average='macro')\n",
    "        f1Score = f1_score(y_true, y_pred)\n",
    "        area_under_c = roc_auc_score(y_true, y_pred)\n",
    "        recallScore = recall_score(y_true, y_pred)\n",
    "        precisionScore = precision_score(y_true, y_pred)\n",
    "\n",
    "        nonhate_f1Score = f1_score(y_true, y_pred, pos_label=0)\n",
    "        non_recallScore = recall_score(y_true, y_pred, pos_label=0)\n",
    "        non_precisionScore = precision_score(y_true, y_pred, pos_label=0)\n",
    "        return {prefix+\"accuracy\": accuracy, prefix+'mF1Score': mf1Score, \n",
    "            prefix+'f1Score': f1Score, prefix+'auc': area_under_c,\n",
    "            prefix+'precision': precisionScore, \n",
    "            prefix+'recall': recallScore, \n",
    "            prefix+'non_hatef1Score': nonhate_f1Score, \n",
    "            prefix+'non_recallScore': non_recallScore, \n",
    "            prefix+'non_precisionScore': non_precisionScore}\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##---------------- Different Train Loops --------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def evaluate(self,model,loader,which):\n",
    "        # to evaluate model on test and validation set\n",
    "\n",
    "        model.eval() # put model in eval mode\n",
    "\n",
    "        # maintain total loss to save in metrics\n",
    "        total_eval_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(loader):\n",
    "            # separate input, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            with torch.no_grad(): # do not construct compute graph\n",
    "                outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "            # output is always a tuple, thus we have to \n",
    "            # separate it manually\n",
    "            #loss = outputs[0]\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # define new loss function so that we can include\n",
    "            # weights\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float).to(self.device))\n",
    "            \n",
    "            loss = loss_fct(logits.view(-1, 2), b_labels.view(-1))\n",
    "\n",
    "            # add the current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # calculate true labels and convert it into numpy array\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "            \n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "        # calculate metrics\n",
    "        metrics = self.evalMetric(y_true,y_pred,which+\"_\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_loss = total_eval_loss / len(loader)\n",
    "        # add it to the metric\n",
    "        metrics[which+'_avg_loss'] = avg_loss\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    def run_train_loop(self,model,train_loader,optimiser,scheduler):\n",
    "\n",
    "        model.train() # put model in train mode\n",
    "\n",
    "        # maintain total loss to add to metric\n",
    "        total_loss = 0\n",
    "\n",
    "        # maintain predictions for each batch and calculate metrics\n",
    "        # at the end of the epoch\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            # separate inputs, labels and attention mask\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            # Ref: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch#:~:text=In%20PyTorch%20%2C%20we%20need%20to,backward()%20call.\n",
    "            model.zero_grad()                \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "            # outputs is always returned as tuple\n",
    "            # Separate it manually\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # define new loss function so that we can include\n",
    "            # weights\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float).to(self.device))\n",
    "            \n",
    "            loss = loss_fct(logits.view(-1, 2), b_labels.view(-1))\n",
    "            \n",
    "            # calculate current loss\n",
    "            # loss.item() extracts loss value as a float\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Back-propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # calculate true labels\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "\n",
    "            # calculate predicted labels by taking max of \n",
    "            # prediction scores\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "            # clip gradient to prevent exploding gradient\n",
    "            # problems\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # gradient descent\n",
    "            optimiser.step()\n",
    "            \n",
    "            # schedule learning rate accordingly\n",
    "            scheduler.step()\n",
    "\n",
    "        # calculate avg loss \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # calculate metrics\n",
    "        train_metrics = self.evalMetric(y_true,y_pred,\"Train_\")\n",
    "        \n",
    "        # print results\n",
    "        print('avg_train_loss',avg_train_loss)\n",
    "        print('train_f1Score',train_metrics['Train_f1Score'])\n",
    "        print('train_accuracy',train_metrics['Train_accuracy'])\n",
    "\n",
    "        # add loss to metrics\n",
    "        train_metrics['Train_avg_loss'] = avg_train_loss\n",
    "\n",
    "        return train_metrics\n",
    "    \n",
    "    \n",
    "    ##------------------------------------------------------------##\n",
    "    ##----------------- Main Train Loop --------------------------##\n",
    "    ##------------------------------------------------------------##\n",
    "    def train(self,model,data_loaders,optimiser,scheduler,epochs,save_model):\n",
    "        # save train stats per epoch\n",
    "        train_stats = []\n",
    "        train_loader,val_loader,test_loader = data_loaders\n",
    "        # maintain best mF1 Score to save best model\n",
    "        best_mf1Score=-1.0\n",
    "        for epoch_i in range(0, epochs):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            \n",
    "            print(\"\")\n",
    "            print('Training...')\n",
    "            # run trian loop\n",
    "            train_metrics = self.run_train_loop(model,train_loader,\n",
    "                                            optimiser,scheduler)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\") \n",
    "            # test on validation set\n",
    "            val_metrics = self.evaluate(model,val_loader,\"Val\")\n",
    "            \n",
    "            print(\"Validation Loss: \",val_metrics['Val_avg_loss'])\n",
    "            print(\"Validation Accuracy: \",val_metrics['Val_accuracy'])\n",
    "            \n",
    "            stats = {}\n",
    "\n",
    "            # save model where validation mF1Score is best\n",
    "            if(val_metrics['Val_mF1Score']>best_mf1Score):\n",
    "                best_mf1Score=val_metrics['Val_mF1Score']\n",
    "                if(save_model):\n",
    "                    torch.save(model.state_dict(), self.model_save_path+\n",
    "                        '/best_bert_'+self.name+'.pt')\n",
    "                # evaluate best model on test set\n",
    "                test_metrics = self.evaluate(model,test_loader,\"Test\")\n",
    "\n",
    "            stats['epoch']=epoch_i+1\n",
    "\n",
    "            # add train and val metrics of the epoch to \n",
    "            # same dictionary\n",
    "            stats.update(train_metrics)\n",
    "            stats.update(val_metrics)\n",
    "\n",
    "            train_stats.append(stats)\n",
    "\n",
    "        return train_stats,test_metrics\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------------- Main Pipeline ---------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run(self,args,df_train,df_val,df_test):\n",
    "        # get X and Y data points \n",
    "        X_train = df_train['Text'].values\n",
    "        Y_train = df_train['Label'].values\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "        X_val = df_val['Text'].values\n",
    "        Y_val = df_val['Label'].values\n",
    "        \n",
    "        # encode data\n",
    "        # returns list of data and attention masks\n",
    "        train_data = self.encode(X_train,args['max_len'])\n",
    "        val_data = self.encode(X_val,args['max_len'])\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "        \n",
    "        # add labels to data so that we can send them to\n",
    "        # dataloader function together\n",
    "        train_data.append(Y_train)\n",
    "        val_data.append(Y_val)\n",
    "        test_data.append(Y_test)\n",
    "        \n",
    "        # convert to dataloader\n",
    "        train_dl =self.get_dataloader(train_data,args['batch_size'],True)\n",
    "        val_dl =self.get_dataloader(val_data,args['batch_size'])                          \n",
    "        test_dl =self.get_dataloader(test_data,args['batch_size'])\n",
    "        \n",
    "        # intialise model\n",
    "#         model = weighted_Roberta.from_pretrained(\n",
    "#             'xlm-roberta-base', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "#             num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.   \n",
    "#             params=args['params'],\n",
    "#         )\n",
    "        model = self.load_model(args['model_path'],args)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        optimiser = self.get_optimiser(args['learning_rate'],model)\n",
    "        \n",
    "        scheduler = self.get_scheduler(args['epochs'],optimiser,train_dl)\n",
    "        \n",
    "        # Run train loop and evaluate on validation data set\n",
    "        # on each epoch. Store best model from all epochs \n",
    "        # (best mF1 Score on Val set) and evaluate it on\n",
    "        # test set\n",
    "        train_stats,train_metrics = self.train(model,[train_dl,val_dl,test_dl],\n",
    "                                optimiser,scheduler,args['epochs'],args['save_model'])\n",
    "        \n",
    "        return train_stats,train_metrics\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##-------------------- Other Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run_test(self,model,df_test,args):\n",
    "        # to evaluate test set on the final saved model\n",
    "        # to retrieve results if necessary\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "\n",
    "        test_data.append(Y_test)\n",
    "\n",
    "        test_dl =self.get_dataloader(test_data,32)\n",
    "\n",
    "        metrics = self.evaluate(model,test_dl,\"Test\")\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def load_model(self,path,args):\n",
    "        # load saved best model\n",
    "        saved_model = weighted_Roberta.from_pretrained(\n",
    "            'xlm-roberta-base', # Use the 12-layer BERT model, with an uncased vocab.\n",
    "            num_labels = 2, # The number of output labels--2 for binary classification             # You can increase this for multi-class tasks.   \n",
    "            params=args['params'],\n",
    "        )\n",
    "        \n",
    "        saved_model.load_state_dict(torch.load(path))\n",
    "        \n",
    "        return saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(args,index):\n",
    "    # initialise constants \n",
    "    path = args['data_path']\n",
    "    # read dataframes\n",
    "    df_train = pd.read_csv(path+'train_'+str(index)+'.csv')\n",
    "    df_val = pd.read_csv(path+'val_'+str(index)+'.csv')\n",
    "    df_test = pd.read_csv(path+'test_'+str(index)+'.csv')\n",
    "\n",
    "    # clean data\n",
    "    df_train=preprocess(df_train,args['isArabic'])\n",
    "    df_val=preprocess(df_val,args['isArabic'])\n",
    "    df_test=preprocess(df_test,args['isArabic'])\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,isArabic):\n",
    "    \n",
    "    X = df['Text']\n",
    "    X_new=[]\n",
    "    if(isArabic):\n",
    "        prep = ArabertPreprocessor('bert-base-arabertv02')\n",
    "        for text in tqdm(X):\n",
    "            text = prep.preprocess(text)\n",
    "            X_new.append(text)\n",
    "    else:\n",
    "        processer = Data_Preprocessing()\n",
    "        for text in tqdm(X):\n",
    "            text= processer.removeEmojis(text)\n",
    "            text = processer.removeUrls(text)\n",
    "            text=processer.removeSpecialChar(text)\n",
    "            X_new.append(text)\n",
    "\n",
    "    df['Text']=X_new\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(path,metrics,which):\n",
    "    df = pd.DataFrame(metrics)\n",
    "    df.to_csv(path+\"_\"+which+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, index,all_test_metrics,model_args):\n",
    "    model_name = args['model_name']\n",
    "    model_args['name']=model_name+'_'+str(index)+'_all'\n",
    "    print(\"\\tInitialising Model....\")\n",
    "    model = XLM_Roberta_fewShot(model_args)\n",
    "    print(\"\\tLoading Dataset....\")\n",
    "    df_train, df_val, df_test = load_dataset(args,index)\n",
    "    print(\"\\tTraining Starts....\")\n",
    "    train_metrics, test_metrics = model.run(model_args, \n",
    "                    df_train, df_val, df_test)\n",
    "\n",
    "    # Save train metrics after generating path\n",
    "    res_path=args['res_base_path']+model_name+'_'+model_args['name']\n",
    "    save_metrics(res_path,train_metrics,\"train\")\n",
    "    \n",
    "    all_test_metrics.append(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args,model_args):\n",
    "    all_test_metrics=[]\n",
    "    \n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"Fold: \",fold)\n",
    "        fix_random()\n",
    "        train(args,fold,all_test_metrics,model_args)\n",
    "        print(\"Saving Test Metrics....\")\n",
    "        save_metrics(args['res_base_path']+args['model_name']+'_all',\n",
    "                     all_test_metrics,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d6b2a5ddc576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         }\n\u001b[1;32m     44\u001b[0m     }\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-65809962ceb3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args, model_args)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfix_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_test_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving Test Metrics....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         save_metrics(args['res_base_path']+args['model_name']+'_all',\n",
      "\u001b[0;32m<ipython-input-10-f0470235ed19>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, index, all_test_metrics, model_args)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_all'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tInitialising Model....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLM_Roberta_fewShot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tLoading Dataset....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9b5bf899c67b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# initiliase tokeniser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlm-roberta-base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_save_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[1;32m   1693\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1403\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Let-Mi/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/Let-Mi/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Let-Mi/',\n",
    "    'isArabic': True,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Let-Mi/all_but_one/best_bert_xlm_roberta_3_all.pt',\n",
    "        'isArabic': True,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/AMI-Spanish/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/AMI-Spanish/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/AMI-Spanish/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/AMI-Spanish/all_but_one/best_bert_xlm_roberta_1_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Shared_Task_hin/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/Shared_Task_hin/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_hin/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 4.5],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Shared_Task_hin/all_but_one/best_bert_xlm_roberta_1_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,4.5],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6948/6948 [00:02<00:00, 2663.31it/s]\n",
      "100%|██████████| 991/991 [00:00<00:00, 2988.85it/s]\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 3069.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 4111/6948 [01:24<01:53, 24.90it/s] "
     ]
    }
   ],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/AMI-2020/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/AMI-2020/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/AMI-2020/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/AMI-2020/all_but_one/best_bert_xlm_roberta_2_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11436/11436 [00:10<00:00, 1066.93it/s]\n",
      "100%|██████████| 1633/1633 [00:01<00:00, 1265.37it/s]\n",
      "100%|██████████| 3266/3266 [00:02<00:00, 1173.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11436/11436 [10:58<00:00, 17.38it/s]\n",
      "100%|██████████| 1633/1633 [00:13<00:00, 120.44it/s]\n",
      "100%|██████████| 3266/3266 [00:54<00:00, 59.84it/s] \n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'roberta.embeddings.position_ids', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1429/1429 [03:53<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.6132239549609124\n",
      "train_f1Score 0.5451943715716671\n",
      "train_accuracy 0.833187543736879\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:07<00:00, 28.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7002191140553823\n",
      "Validation Accuracy:  0.8774509803921569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:14<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1429/1429 [03:54<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.573414663825265\n",
      "train_f1Score 0.5913583733408642\n",
      "train_accuracy 0.8734254723582925\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:07<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.5353236360219764\n",
      "Validation Accuracy:  0.8774509803921569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:14<00:00, 28.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 706/1429 [01:55<01:59,  6.05it/s]"
     ]
    }
   ],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Shared_Task_eng/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/Shared_Task_eng/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_eng/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 8.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Shared_Task_eng/all_but_one/best_bert_xlm_roberta_4_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,8.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bengali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Shared_Task_iben/',\n",
    "    'train_cnt':'all',\n",
    "    'res_base_path': 'Results/Shared_Task_iben/fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_iben/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda:1',\n",
    "        'weights': [1.0, 6.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Shared_Task_iben/all_but_one/best_bert_xlm_roberta_5_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,6.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less data points few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_part(train_cnt,args,index,seed):\n",
    "    # initialise constants \n",
    "    path = args['data_path']\n",
    "    # read dataframes\n",
    "    df_train = pd.read_csv(path+'train_'+str(index)+'.csv')\n",
    "    df_val = pd.read_csv(path+'val_'+str(index)+'.csv')\n",
    "    df_test = pd.read_csv(path+'test_'+str(index)+'.csv')\n",
    "    \n",
    "    # split train into hate and non-hate and take train_cnt\n",
    "    # samples of each\n",
    "    df_train_hate = df_train[df_train['Label'] == 1].sample(train_cnt,random_state=seed)\n",
    "    df_train_non_hate = df_train[df_train['Label'] == 0].sample(train_cnt,random_state=seed)\n",
    "    # concatenate hate and non_hate\n",
    "    df_train = pd.concat([df_train_hate, df_train_non_hate])\n",
    "    # shuffle the train data\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # clean data\n",
    "    df_train=preprocess(df_train,args['isArabic'])\n",
    "    df_val=preprocess(df_val,args['isArabic'])\n",
    "    df_test=preprocess(df_test,args['isArabic'])\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part(args,train_cnt,run,index,all_test_metrics,model_args,seed):\n",
    "    model_name = args['model_name']\n",
    "    model_args['name']=model_name+'_'+str(index)+'_'+str(train_cnt)+'_'+str(run)\n",
    "    print(\"\\tInitialising Model....\")\n",
    "    model = XLM_Roberta_fewShot(model_args)\n",
    "    print(\"\\tLoading Dataset....\")\n",
    "    df_train, df_val, df_test = load_dataset_part(train_cnt,args,index,seed)\n",
    "    print(\"\\tTraining Starts....\")\n",
    "    train_metrics, test_metrics = model.run(model_args, \n",
    "                    df_train, df_val, df_test)\n",
    "\n",
    "    # Save train metrics after generating path\n",
    "    res_path=args['res_base_path']+model_name+'_'+model_args['name']\n",
    "    save_metrics(res_path,train_metrics,\"train\")\n",
    "    \n",
    "    all_test_metrics.append(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_part(run_args,model_args,train_cnt):\n",
    "    all_test_metrics=[]\n",
    "    seeds = [42,43,44]\n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        print(\"Fold: \",fold)\n",
    "        for run in [1,2,3]:\n",
    "            print(\"Run: \",run)\n",
    "            fix_random()\n",
    "            train_part(run_args,train_cnt,run,fold,all_test_metrics,model_args,seeds[run-1])\n",
    "            print(\"Saving Test Metrics....\")\n",
    "            save_metrics(run_args['res_base_path']+run_args['model_name']+\n",
    "                         '_'+str(train_cnt),all_test_metrics,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic few data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "Run:  1\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 4878.34it/s]\n",
      "100%|██████████| 523/523 [00:00<00:00, 5487.62it/s]\n",
      "100%|██████████| 1047/1047 [00:00<00:00, 7058.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 861.19it/s]\n",
      "100%|██████████| 523/523 [00:02<00:00, 203.89it/s]\n",
      "100%|██████████| 1047/1047 [00:10<00:00, 103.16it/s]\n",
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "/home/mithundas/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing weighted_Roberta: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing weighted_Roberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing weighted_Roberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of weighted_Roberta were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b03106da79d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         }\n\u001b[1;32m     44\u001b[0m     }\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mrun_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-56e766301abf>\u001b[0m in \u001b[0;36mrun_part\u001b[0;34m(run_args, model_args, train_cnt)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mfix_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtrain_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_test_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving Test Metrics....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             save_metrics(run_args['res_base_path']+run_args['model_name']+\n",
      "\u001b[0;32m<ipython-input-14-cbe4edc4a82b>\u001b[0m in \u001b[0;36mtrain_part\u001b[0;34m(args, train_cnt, run, index, all_test_metrics, model_args, seed)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tTraining Starts....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     train_metrics, test_metrics = model.run(model_args, \n\u001b[0m\u001b[1;32m     10\u001b[0m                     df_train, df_val, df_test)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9b5bf899c67b>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, args, df_train, df_val, df_test)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;31m#         )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Let-Mi/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Let-Mi/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Let-Mi/',\n",
    "    'isArabic': True,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Let-Mi/all_but_one/best_bert_xlm_roberta_3_all.pt',\n",
    "        'isArabic': True,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':True,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':True,\n",
    "            'weights':[1.0,1.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "run_part(run_args,model_args,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Italian few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "Run:  1\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 2419.84it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|███▎      | 334/991 [00:00<00:00, 3332.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 991/991 [00:00<00:00, 3406.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 348/1983 [00:00<00:00, 3479.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 715/1983 [00:00<00:00, 3533.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 1080/1983 [00:00<00:00, 3563.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1450/1983 [00:00<00:00, 3603.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 3575.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 4486.41it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 385/991 [00:00<00:00, 3848.00it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:00<00:00, 3894.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 407/1983 [00:00<00:00, 4069.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 822/1983 [00:00<00:00, 4092.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 1242/1983 [00:00<00:00, 4123.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 4077.94it/s]\u001b[A\u001b[A\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 48.88it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 1.1001893728971481\n",
      "train_f1Score 0.05714285714285714\n",
      "train_accuracy 0.484375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 48.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 48.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 47.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 47.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:01, 47.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 47.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 47.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 47.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 47.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 47.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 47.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 47.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 47.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 47.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 47.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 47.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 47.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:01<00:00, 47.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 47.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 47.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 47.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 47.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 47.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 48.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.8366757845733224\n",
      "Validation Accuracy:  0.5304878048780488\n",
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:04, 47.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:04, 47.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 47.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 47.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 47.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 47.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 47.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 47.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 47.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 47.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:03, 47.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:03, 47.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 47.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 47.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 47.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 47.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 47.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 47.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 47.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 47.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:02, 47.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 47.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 47.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 47.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 47.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 47.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:02<00:02, 47.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 47.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 47.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:01, 47.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 47.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 47.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 47.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 47.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 47.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:03<00:01, 47.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 47.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 47.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:00, 47.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 47.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 47.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 47.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 47.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 47.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:04<00:00, 47.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:04<00:00, 46.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 46.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 47.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.91it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 48.19it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.7565140500664711\n",
      "train_f1Score 0.3255813953488372\n",
      "train_accuracy 0.546875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 47.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 47.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 47.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 47.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:01, 47.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 47.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 47.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 46.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 46.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 46.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 46.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 46.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 46.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 46.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 46.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 46.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 46.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 46.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 46.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 46.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 46.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 46.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 46.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 47.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6856275331683275\n",
      "Validation Accuracy:  0.5894308943089431\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 47.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:04, 47.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 47.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 46.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 47.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 46.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 46.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 46.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 46.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 46.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 46.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:03, 46.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 46.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 46.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 46.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 46.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 46.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 46.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 46.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:02, 46.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 46.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 46.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 46.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 46.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 46.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 46.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 46.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 46.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:01, 46.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 46.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 46.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 46.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 46.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 46.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:03<00:01, 46.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 46.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 46.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 46.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 46.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 46.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 46.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 46.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 46.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:04<00:00, 46.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 46.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 46.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 46.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 47.34it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 47.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:04, 46.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 46.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 46.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 46.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 46.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 46.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 46.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 46.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 46.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 46.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:03, 46.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 46.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 46.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 46.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 46.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 46.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 46.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 46.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 46.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:02, 46.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 46.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 46.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 46.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 46.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 46.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:01, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 46.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 46.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 46.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 46.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 46.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:03<00:01, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 46.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 46.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 46.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 46.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 46.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 46.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 46.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 46.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:04<00:00, 46.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 46.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 46.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 46.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.77it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 47.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.6849025785923004\n",
      "train_f1Score 0.53125\n",
      "train_accuracy 0.53125\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 47.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 46.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 46.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 46.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 46.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 46.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 46.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 46.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 46.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 46.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 46.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 46.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 46.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 46.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 46.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 46.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 46.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 46.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 46.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.76it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6618457746699573\n",
      "Validation Accuracy:  0.5985772357723578\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 47.25it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.552492044866085\n",
      "train_f1Score 0.7936507936507936\n",
      "train_accuracy 0.796875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 46.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 46.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 46.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 46.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 46.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 46.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 45.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 45.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 45.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 45.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 45.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 45.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 45.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 45.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 45.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 45.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 45.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 45.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 45.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 45.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 45.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 45.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 46.61it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6551991340106096\n",
      "Validation Accuracy:  0.6361788617886179\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 46.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 46.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 46.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 45.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 45.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 45.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 45.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:03, 45.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 45.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 45.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 45.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 45.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 45.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 45.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 45.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 45.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 45.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 45.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 45.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 45.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 45.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 45.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 45.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 45.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 45.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 45.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 45.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 45.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 45.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 45.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 45.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 46.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 46.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 45.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 45.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 45.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 45.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 45.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 45.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 45.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 45.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 45.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 45.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 45.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 45.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.78it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.4307372123003006\n",
      "train_f1Score 0.911764705882353\n",
      "train_accuracy 0.90625\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6636197000015073\n",
      "Validation Accuracy:  0.6453252032520326\n",
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 46.10it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.33883108012378216\n",
      "train_f1Score 0.9375\n",
      "train_accuracy 0.9375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6833020134912273\n",
      "Validation Accuracy:  0.649390243902439\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.58it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 46.08it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.25378212332725525\n",
      "train_f1Score 0.9523809523809523\n",
      "train_accuracy 0.953125\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7585998669387849\n",
      "Validation Accuracy:  0.6351626016260162\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.60it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.2678301874548197\n",
      "train_f1Score 0.9411764705882353\n",
      "train_accuracy 0.9375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.8025166382634543\n",
      "Validation Accuracy:  0.6361788617886179\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 46.14it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.19670867547392845\n",
      "train_f1Score 0.9846153846153847\n",
      "train_accuracy 0.984375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7877049620558576\n",
      "Validation Accuracy:  0.6453252032520326\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.82it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.19381932727992535\n",
      "train_f1Score 0.9846153846153847\n",
      "train_accuracy 0.984375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.16it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7876894455857393\n",
      "Validation Accuracy:  0.641260162601626\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.85it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Test Metrics....\n",
      "Run:  2\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 4022.83it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 335/991 [00:00<00:00, 3335.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 991/991 [00:00<00:00, 3404.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 347/1983 [00:00<00:00, 3462.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 715/1983 [00:00<00:00, 3523.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 1087/1983 [00:00<00:00, 3578.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1451/1983 [00:00<00:00, 3590.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 3572.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 4149.50it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 375/991 [00:00<00:00, 3744.79it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:00<00:00, 3861.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 405/1983 [00:00<00:00, 4042.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 814/1983 [00:00<00:00, 4055.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1225/1983 [00:00<00:00, 4068.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 4050.04it/s]\u001b[A\u001b[A\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 47.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 1.0545953065156937\n",
      "train_f1Score 0.25\n",
      "train_accuracy 0.4375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 46.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 46.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 46.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 46.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 46.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 46.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 46.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 45.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 45.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 45.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 45.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 45.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 46.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 46.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 46.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 45.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 45.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 45.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 45.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 45.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 45.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 45.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 45.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 46.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7324313281512842\n",
      "Validation Accuracy:  0.5223577235772358\n",
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 46.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 46.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 46.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 45.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 45.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 45.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 45.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 45.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:03, 45.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 45.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 45.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 45.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 45.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 45.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 45.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 45.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 45.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 45.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 45.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 45.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 45.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 45.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 45.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 45.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 45.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 45.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 45.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 45.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 45.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 45.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 45.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 45.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 45.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.71it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 46.89it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.6408836767077446\n",
      "train_f1Score 0.6857142857142857\n",
      "train_accuracy 0.65625\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 46.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 46.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 46.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 45.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:00<00:01, 45.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 45.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 45.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 45.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 45.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 45.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 45.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 45.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:01<00:00, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 45.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 45.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 45.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 45.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 46.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6708171692320971\n",
      "Validation Accuracy:  0.5589430894308943\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:04, 45.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 45.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:00<00:04, 45.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 45.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 45.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 45.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 45.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 45.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 45.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:01<00:03, 45.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 45.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 45.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 45.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 45.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:02<00:02, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 45.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 45.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 45.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:03<00:01, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:04<00:00, 45.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 45.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 45.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:00<00:00, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 46.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.5591603629291058\n",
      "train_f1Score 0.7692307692307692\n",
      "train_accuracy 0.765625\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6712457622454419\n",
      "Validation Accuracy:  0.6067073170731707\n",
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.34it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:00<00:00, 10.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:00<00:00, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.75it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.4099707920104265\n",
      "train_f1Score 0.8615384615384615\n",
      "train_accuracy 0.859375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 44.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.6965522813360866\n",
      "Validation Accuracy:  0.6178861788617886\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 44.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 44.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 44.75it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.27938369009643793\n",
      "train_f1Score 0.9180327868852458\n",
      "train_accuracy 0.921875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7642469804097967\n",
      "Validation Accuracy:  0.616869918699187\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.2416942873969674\n",
      "train_f1Score 0.9333333333333333\n",
      "train_accuracy 0.9375\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.9330049436387977\n",
      "Validation Accuracy:  0.6280487804878049\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:00<00:00, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:00<00:00, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:00<00:00, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.07it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.23479019198566675\n",
      "train_f1Score 0.9206349206349206\n",
      "train_accuracy 0.921875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.0178559758071977\n",
      "Validation Accuracy:  0.6239837398373984\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.22964584175497293\n",
      "train_f1Score 0.9206349206349206\n",
      "train_accuracy 0.921875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.0223667839678323\n",
      "Validation Accuracy:  0.6300813008130082\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mF1Score....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 45.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:00<00:00, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 4/8 [00:00<00:00, 10.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:00<00:00, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:00<00:00, 10.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:00<00:00, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.1877595642581582\n",
      "train_f1Score 0.9508196721311475\n",
      "train_accuracy 0.953125\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 44.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 2/8 [00:00<00:00, 10.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.016498558404969\n",
      "Validation Accuracy:  0.6270325203252033\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:00<00:00, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:00<00:00, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/123 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 5/123 [00:00<00:02, 45.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.1775457877665758\n",
      "train_f1Score 0.9508196721311475\n",
      "train_accuracy 0.953125\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 10/123 [00:00<00:02, 45.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 15/123 [00:00<00:02, 45.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 20/123 [00:00<00:02, 45.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 25/123 [00:00<00:02, 45.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 30/123 [00:00<00:02, 45.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 35/123 [00:00<00:01, 44.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 40/123 [00:00<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 45/123 [00:01<00:01, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 50/123 [00:01<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 55/123 [00:01<00:01, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 60/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 65/123 [00:01<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 70/123 [00:01<00:01, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 75/123 [00:01<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 80/123 [00:01<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 85/123 [00:01<00:00, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 90/123 [00:02<00:00, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 95/123 [00:02<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 100/123 [00:02<00:00, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 105/123 [00:02<00:00, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 110/123 [00:02<00:00, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 115/123 [00:02<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 123/123 [00:02<00:00, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/247 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/247 [00:00<00:05, 45.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.0110588555898123\n",
      "Validation Accuracy:  0.6290650406504065\n",
      "Testing Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 10/247 [00:00<00:05, 45.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/247 [00:00<00:05, 45.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/247 [00:00<00:05, 44.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/247 [00:00<00:04, 44.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/247 [00:00<00:04, 44.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/247 [00:00<00:04, 44.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/247 [00:00<00:04, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/247 [00:01<00:04, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/247 [00:01<00:04, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/247 [00:01<00:04, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/247 [00:01<00:04, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 65/247 [00:01<00:04, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/247 [00:01<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/247 [00:01<00:03, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/247 [00:01<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/247 [00:01<00:03, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 90/247 [00:02<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/247 [00:02<00:03, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/247 [00:02<00:03, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 105/247 [00:02<00:03, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 110/247 [00:02<00:03, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 115/247 [00:02<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 120/247 [00:02<00:02, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 125/247 [00:02<00:02, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 130/247 [00:02<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 135/247 [00:03<00:02, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 140/247 [00:03<00:02, 44.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 145/247 [00:03<00:02, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 150/247 [00:03<00:02, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 155/247 [00:03<00:02, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 160/247 [00:03<00:01, 44.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 165/247 [00:03<00:01, 44.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 170/247 [00:03<00:01, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 175/247 [00:03<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 180/247 [00:04<00:01, 44.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 185/247 [00:04<00:01, 44.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 190/247 [00:04<00:01, 44.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 195/247 [00:04<00:01, 44.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 200/247 [00:04<00:01, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 205/247 [00:04<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 210/247 [00:04<00:00, 44.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 215/247 [00:04<00:00, 44.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 220/247 [00:04<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 225/247 [00:05<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 230/247 [00:05<00:00, 44.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 235/247 [00:05<00:00, 44.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 240/247 [00:05<00:00, 44.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 247/247 [00:05<00:00, 44.82it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Test Metrics....\n",
      "Run:  3\n",
      "\tInitialising Model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 3644.99it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 337/991 [00:00<00:00, 3367.08it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading Dataset....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 991/991 [00:00<00:00, 3413.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 347/1983 [00:00<00:00, 3460.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 711/1983 [00:00<00:00, 3506.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 1080/1983 [00:00<00:00, 3556.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1450/1983 [00:00<00:00, 3591.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 3562.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 3661.65it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/991 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 368/991 [00:00<00:00, 3678.24it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Starts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 991/991 [00:00<00:00, 3810.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1983 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 407/1983 [00:00<00:00, 4065.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 817/1983 [00:00<00:00, 4075.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1225/1983 [00:00<00:00, 4075.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1983/1983 [00:00<00:00, 4021.30it/s]\u001b[A\u001b[A\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/AMI-2020/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/AMI-2020/fewData_fewShot/',\n",
    "    'model_save_path': 'Saved_Models/AMI-2020/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run_part(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/AMI-Spanish/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/AMI-Spanish/fewData_fewShot/',\n",
    "    'model_save_path': 'Saved_Models/AMI-Spanish/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run_part(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_hin/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_hin/fewData_fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_hin/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run_part(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bengali Few Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot',\n",
    "    'data_path':'Data_Processed/Shared_Task_iben/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_iben/fewData_fewShot/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_iben/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"bert-base-multilingual-cased\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 1.0],\n",
    "        'save_model': False,\n",
    "        'model_save_path': '',\n",
    "        'isArabic': False,\n",
    "        'model_path': \"Saved_Models/Shared_Task_eng_1/best_bert_3_all.pt\",\n",
    "    }\n",
    "run_part(run_args,model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_args={\n",
    "    'model_name':'few_shot_xlm',\n",
    "    'data_path':'Data_Processed/Shared_Task_eng/',\n",
    "    'train_cnt':256,\n",
    "    'res_base_path': 'Results/Shared_Task_eng/all_but_one/',\n",
    "    'model_save_path': 'Saved_Models/Shared_Task_eng/',\n",
    "    'isArabic': False,\n",
    "}\n",
    "\n",
    "model_args={\n",
    "        'seed_val': 42,\n",
    "        'name': 'xlm_roberta',\n",
    "        'batch_size': 8,\n",
    "        'bert_model': \"xlm-roberta-base\",\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 10,\n",
    "        'max_len': 128,\n",
    "        'device': 'cuda',\n",
    "        'weights': [1.0, 8.0],\n",
    "        'save_model': False,\n",
    "        'model_path': 'Saved_Models/Shared_Task_eng/all_but_one/best_bert_xlm_roberta_4_all.pt',\n",
    "        'isArabic': False,\n",
    "        'model_save_path': '',\n",
    "        'max_length':128,\n",
    "        'is_train':True,\n",
    "        'epsilon':1e-8,\n",
    "        'random_seed':30,\n",
    "        'to_save':False,\n",
    "        'frac':0.8,\n",
    "        'params':{\n",
    "            'max_length':128,\n",
    "            'path_files': 'xlm-roberta-base',\n",
    "            'what_bert':'weighted',\n",
    "            'batch_size':8,\n",
    "            'is_train':True,\n",
    "            'learning_rate':2e-5,\n",
    "            'epsilon':1e-8,\n",
    "            'random_seed':30,\n",
    "            'epochs':10,\n",
    "            'to_save':False,\n",
    "            'weights':[1.0,8.0],\n",
    "            'frac':0.8\n",
    "        }\n",
    "    }\n",
    "\n",
    "for train_cnt in [32,64,128,256,512]:\n",
    "    print(\"Train cnt: \",train_cnt)\n",
    "    run_args['train_cnt']=train_cnt\n",
    "    run_part(run_args,model_args,train_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
