{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# # If there's a GPU available...\n",
    "# if torch.cuda.is_available():    \n",
    "\n",
    "#     # Tell PyTorch to use the GPU.    \n",
    "#     device = torch.device(\"cuda\")\n",
    "\n",
    "#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# # If not...\n",
    "# else:\n",
    "print('No GPU available, using the CPU instead.')\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"Data/Shared Task/eng/\"\n",
    "FILE_NAME = \"trac2_eng_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FOLDER+FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  4263\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: \",df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sub-task A</th>\n",
       "      <th>Sub-task B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>C4.152</td>\n",
       "      <td>This is soo true üíØüíØüíØüíØüíØ‚ù§ bhai..u are best..</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>C4.1086.5</td>\n",
       "      <td>You saved my dude broüòÇüòÇüòÇüòÇü§£ü§£ü§£</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>C4.1372</td>\n",
       "      <td>if movies are like our real life why making mo...</td>\n",
       "      <td>CAG</td>\n",
       "      <td>GEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>C59.163</td>\n",
       "      <td>Just mind blowing üëå</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>C33.617</td>\n",
       "      <td>wow nice video !!</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>C4.2109</td>\n",
       "      <td>Correct‚ù§</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>C10.534</td>\n",
       "      <td>She can write her father name in npr ranga billa.</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>C7.1583</td>\n",
       "      <td>Haha what a joke..u should not speak dude</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>C68.402</td>\n",
       "      <td>Ranu.nice</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>C59.1201</td>\n",
       "      <td>Love you vaiya nice video.i love you</td>\n",
       "      <td>NAG</td>\n",
       "      <td>NGEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text Sub-task A  \\\n",
       "650      C4.152         This is soo true üíØüíØüíØüíØüíØ‚ù§ bhai..u are best..        NAG   \n",
       "3739  C4.1086.5                       You saved my dude broüòÇüòÇüòÇüòÇü§£ü§£ü§£        NAG   \n",
       "1099    C4.1372  if movies are like our real life why making mo...        CAG   \n",
       "4152    C59.163                                Just mind blowing üëå        NAG   \n",
       "2271    C33.617                                  wow nice video !!        NAG   \n",
       "1141    C4.2109                                           Correct‚ù§        NAG   \n",
       "4043    C10.534  She can write her father name in npr ranga billa.        NAG   \n",
       "3459    C7.1583          Haha what a joke..u should not speak dude        NAG   \n",
       "3918    C68.402                                          Ranu.nice        NAG   \n",
       "488    C59.1201               Love you vaiya nice video.i love you        NAG   \n",
       "\n",
       "     Sub-task B  \n",
       "650        NGEN  \n",
       "3739       NGEN  \n",
       "1099        GEN  \n",
       "4152       NGEN  \n",
       "2271       NGEN  \n",
       "1141       NGEN  \n",
       "4043       NGEN  \n",
       "3459       NGEN  \n",
       "3918       NGEN  \n",
       "488        NGEN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.Text.values\n",
    "labels = df['Sub-task B'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NGEN', 'NGEN', 'NGEN', 'NGEN', 'NGEN', 'NGEN', 'NGEN', 'NGEN',\n",
       "       'NGEN', 'NGEN'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert labels into 0s and 1s as model cannot take string input\n",
    "- 0: NGEN\n",
    "- 1: GEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_int=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    if(label=='NGEN'): \n",
    "        labels_int.append(0)\n",
    "    else:\n",
    "        labels_int.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "Sub-Task 2 is related to Misogyny detection\n",
    "- GEN: Gendered or Misogynous\n",
    "- NGEN: Non-gendered or Non-Misogynous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NGEN', 'GEN'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sub-task B'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Hindi old muvi\n",
      "Tokenized:  ['Hindi', 'old', 'mu', '##vi']\n",
      "Token IDs:  [31341, 12898, 12361, 11310]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[10])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[10]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying  tokenisation with emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Megha here üòÇüòÇ\n",
      "Tokenized:  ['Meg', '##ha', 'here', '[UNK]']\n",
      "Token IDs:  [77499, 10921, 19353, 100]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[2867])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[2867]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[2867])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing them is better. But let's get a baseline result with them too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting input\n",
    "We are required to:\n",
    "\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the ‚Äúattention mask‚Äù.\n",
    "\n",
    "I am taking 100 as max length. Look at  `Visualising Data Notebook` for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special [CLS] and [SEP] tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from [PAD] tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "# The ‚ÄúAttention Mask‚Äù is simply an array of 1s and 0s indicating\n",
    "# which tokens are padding and which aren‚Äôt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                    sent,\n",
    "                    add_special_tokens =True, # for [CLS] and [SEP]\n",
    "                    max_length = MAX_LEN,\n",
    "                    truncation = True,\n",
    "                    padding = 'max_length',\n",
    "                    return_attention_mask = True,\n",
    "                    return_tensors = 'pt', # return pytorch tensors\n",
    "    )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "input_ids_copy = copy.deepcopy(input_ids)\n",
    "attention_masks_copy = copy.deepcopy(attention_masks)\n",
    "labels_copy = copy.deepcopy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids_copy\n",
    "attention_masks = attention_masks_copy\n",
    "labels = labels_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Hindi old muvi\n",
      "Token IDs: tensor([  101, 31341, 12898, 12361, 11310,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[10])\n",
    "print('Token IDs:', input_ids[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4263, 100]), torch.Size([4263, 100]), torch.Size([4263]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape,attention_masks.shape,labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,410 training samples\n",
      "  853 validation samples\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = BATCH_SIZE # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = BATCH_SIZE # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\", \n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.  \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimiser and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5 # other options 5e-5,3e-5\n",
    "EPOCHS = 4 # other options 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "### Training:\n",
    "\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass.\n",
    "    -In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "### Evalution:\n",
    "\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training code is based on the `run_glue.py` script here:\n",
    "https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, EPOCHS):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    \n",
    "    model.train()  # set the model to training mode\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "    \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad() \n",
    "        \n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward() # perform a backward pass\n",
    "        \n",
    "        # clip graidents to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\") \n",
    "    \n",
    "    model.eval() # put model in eval mode\n",
    "    \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    \n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad(): # do not construct compute graph\n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(data=training_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur.\n",
       "epoch                                           \n",
       "1               0.25         0.21           0.92\n",
       "2               0.18         0.20           0.93\n",
       "3               0.12         0.28           0.90\n",
       "4               0.09         0.29           0.92"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import random\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Tokeniser\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Scheduler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Optimiser\n",
    "from transformers import AdamW\n",
    "\n",
    "# Model\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT:\n",
    "    def __init__(self,args):\n",
    "        # fix the random\n",
    "        random.seed(args['seed_val'])\n",
    "        np.random.seed(args['seed_val'])\n",
    "        torch.manual_seed(args['seed_val'])\n",
    "        torch.cuda.manual_seed_all(args['seed_val'])\n",
    "                \n",
    "        self.device = torch.device(args['device'])\n",
    "        self.weights=args['weights']\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(args['bert_model'])\n",
    "        \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Utility Functions -----------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def encode(self,data,max_len):\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for sent in tqdm(data):\n",
    "            encoded_dict = self.tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens =True, # for [CLS] and [SEP]\n",
    "                            max_length = max_len,\n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt', # return pytorch tensors\n",
    "            )\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "        return [input_ids,attention_masks]\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##------------------ Dataloader -----------------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def get_dataloader(self,samples, batch_size,is_train=False):\n",
    "        inputs,masks,labels = samples\n",
    "\n",
    "        # Convert the lists into tensors.\n",
    "        inputs = torch.cat(inputs, dim=0)\n",
    "        masks = torch.cat(masks, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        data = TensorDataset(inputs,masks,labels)\n",
    "\n",
    "        if(is_train==False):\n",
    "            sampler = SequentialSampler(data)\n",
    "        else:\n",
    "            sampler = RandomSampler(data)  \n",
    "\n",
    "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "        return dataloader\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------- Training Utilities ----------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def get_optimiser(self,learning_rate,model):\n",
    "        return AdamW(model.parameters(),\n",
    "                  lr = learning_rate, \n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "    def get_scheduler(self,epochs,optimiser,train_dl):\n",
    "        total_steps = len(train_dl) * epochs\n",
    "        return get_linear_schedule_with_warmup(optimiser, \n",
    "                num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                num_training_steps = total_steps)\n",
    "    \n",
    "    def evalMetric(self,y_true, y_pred,prefix):\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        mf1Score = f1_score(y_true, y_pred, average='macro')\n",
    "        f1Score  = f1_score(y_true, y_pred, labels = np.unique(y_pred))\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        area_under_c = auc(fpr, tpr)\n",
    "        recallScore = recall_score(y_true, y_pred, labels = np.unique(y_pred))\n",
    "        precisionScore = precision_score(y_true, y_pred, labels = np.unique(y_pred))\n",
    "        return dict({prefix+\"accuracy\": accuracy, prefix+'mF1Score': mf1Score, \n",
    "                        prefix+'f1Score': f1Score, prefix+'precision': precisionScore, \n",
    "                        prefix+'recall': recallScore})\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##---------------- Different Train Loops --------------------##\n",
    "    ##-----------------------------------------------------------## \n",
    "    def evaluate(self,model,loader,which):\n",
    "    \n",
    "        model.eval() # put model in eval mode\n",
    "\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for batch in loader:\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            with torch.no_grad(): # do not construct compute graph\n",
    "                outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "        metrics = self.evalMetric(y_true,y_pred,which+\"_\")\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_loss = total_eval_loss / len(loader)\n",
    "\n",
    "        metrics[which+'_avg_loss'] = avg_loss\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    \n",
    "    def run_train_loop(self,model,train_loader,optimiser,scheduler):\n",
    "        \n",
    "        total_loss = 0\n",
    "        model.train() # put model in train mode\n",
    "\n",
    "        y_pred = np.zeros(shape=(0),dtype='int')\n",
    "        y_true = np.empty(shape=(0),dtype='int')\n",
    "\n",
    "        for step, batch in tqdm(enumerate(train_loader)):\n",
    "\n",
    "            b_input_ids = batch[0].to(self.device)\n",
    "            b_input_mask = batch[1].to(self.device)\n",
    "            b_labels = batch[2].to(self.device)\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "            logits = outputs[1]\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(\n",
    "                        self.weights,dtype=torch.float))\n",
    "            \n",
    "            loss = loss_fct(logits,b_labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            b_y_true = b_labels.cpu().data.squeeze().numpy()\n",
    "\n",
    "            b_y_pred = torch.max(logits,1)[1]\n",
    "            b_y_pred = b_y_pred.cpu().data.squeeze().numpy()\n",
    "\n",
    "            y_pred = np.concatenate((y_pred,b_y_pred))\n",
    "            y_true = np.concatenate((y_true,b_y_true))\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimiser.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        train_metrics = self.evalMetric(y_true,y_pred,\"Train_\")\n",
    "\n",
    "        print('avg_train_loss',avg_train_loss)\n",
    "        print('train_f1Score',train_metrics['Train_f1Score'])\n",
    "        print('train_accuracy',train_metrics['Train_accuracy'])\n",
    "\n",
    "        train_metrics['Train_avg_loss'] = avg_train_loss\n",
    "\n",
    "        return train_metrics\n",
    "    \n",
    "    \n",
    "    ##------------------------------------------------------------##\n",
    "    ##----------------- Main Train Loop --------------------------##\n",
    "    ##------------------------------------------------------------##\n",
    "    def train(self,model,data_loaders,optimiser,scheduler,epochs):\n",
    "        train_stats = []\n",
    "        train_loader,val_loader,test_loader = data_loaders\n",
    "        for epoch_i in range(0, epochs):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            \n",
    "            print(\"\")\n",
    "            print('Training...')\n",
    "            train_metrics = self.run_train_loop(model,train_loader,\n",
    "                                            optimiser,scheduler)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\") \n",
    "            val_metrics = self.evaluate(model,val_loader,\"Val\")\n",
    "            \n",
    "            print(\"Validation Loss: \",val_metrics['Val_avg_loss'])\n",
    "            print(\"Validation Accuracy: \",val_metrics['Val_accuracy'])\n",
    "            \n",
    "            stats = {}\n",
    "\n",
    "            stats['epoch']=epoch_i+1\n",
    "\n",
    "            stats.update(train_metrics)\n",
    "            stats.update(val_metrics)\n",
    "\n",
    "            train_stats.append(stats)\n",
    "\n",
    "        return train_stats\n",
    "    \n",
    "    ##-----------------------------------------------------------##\n",
    "    ##----------------------- Main Pipeline ---------------------##\n",
    "    ##-----------------------------------------------------------##\n",
    "    def run(self,args,df_train,df_val,df_test):\n",
    "        X_train = df_train['Text'].values\n",
    "        Y_train = df_train['Label'].values\n",
    "        X_test = df_test['Text'].values\n",
    "        Y_test = df_test['Label'].values\n",
    "        X_val = df_val['Text'].values\n",
    "        Y_val = df_val['Label'].values\n",
    "        \n",
    "        train_data = self.encode(X_train,args['max_len'])\n",
    "        val_data = self.encode(X_val,args['max_len'])\n",
    "        test_data = self.encode(X_test,args['max_len'])\n",
    "        \n",
    "        train_data.append(Y_train)\n",
    "        val_data.append(Y_val)\n",
    "        test_data.append(Y_test)\n",
    "        \n",
    "        train_dl =self.get_dataloader(train_data,args['batch_size'],True)\n",
    "        val_dl =self.get_dataloader(val_data,args['batch_size'])                          \n",
    "        test_dl =self.get_dataloader(test_data,args['batch_size'])\n",
    "        \n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "                args['bert_model'], \n",
    "                num_labels = 2, \n",
    "                output_attentions = False, # Whether the model returns attentions weights.\n",
    "                output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "            )\n",
    "        \n",
    "        optimiser = self.get_optimiser(args['learning_rate'],model)\n",
    "        \n",
    "        scheduler = self.get_scheduler(args['epochs'],optimiser,train_dl)\n",
    "        \n",
    "        train_stats = self.train(model,[train_dl,val_dl,test_dl],\n",
    "                                optimiser,scheduler,args['epochs'])\n",
    "        \n",
    "        return train_stats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"Data_Processed/Shared_Task_eng/\"\n",
    "\n",
    "df_train = pd.read_csv(DATA_FOLDER+\"train_1.csv\")\n",
    "df_val = pd.read_csv(DATA_FOLDER+\"val_1.csv\")\n",
    "df_test = pd.read_csv(DATA_FOLDER+\"test_1.csv\")\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_val.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.iloc[0:128]\n",
    "df_val=df_val.iloc[0:32]\n",
    "df_test=df_test.iloc[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    'seed_val': 42,\n",
    "    'batch_size':32,\n",
    "    'bert_model': \"bert-base-multilingual-cased\",\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 4,\n",
    "    'max_len': 100,\n",
    "    'device': 'cpu',\n",
    "    'weights':[1.0,5.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERT(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1663.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 1529.67it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 1855.42it/s]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:21,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.6627405136823654\n",
      "train_f1Score 0.20833333333333334\n",
      "train_accuracy 0.703125\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.5316233038902283\n",
      "Validation Accuracy:  0.6875\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:20,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.5979474037885666\n",
      "train_f1Score 0.23999999999999996\n",
      "train_accuracy 0.8515625\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.3841923475265503\n",
      "Validation Accuracy:  0.9375\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:21,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.5398473590612411\n",
      "train_f1Score 0.39999999999999997\n",
      "train_accuracy 0.9296875\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.3392186760902405\n",
      "Validation Accuracy:  0.9375\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:20,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.5437285602092743\n",
      "train_f1Score 0.3076923076923077\n",
      "train_accuracy 0.9296875\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss:  0.33620166778564453\n",
      "Validation Accuracy:  0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Train_accuracy': 0.703125,\n",
       "  'Train_mF1Score': 0.5128205128205129,\n",
       "  'Train_f1Score': 0.20833333333333334,\n",
       "  'Train_precision': 0.13513513513513514,\n",
       "  'Train_recall': 0.45454545454545453,\n",
       "  'Train_avg_loss': 0.6627405136823654,\n",
       "  'Val_accuracy': 0.6875,\n",
       "  'Val_mF1Score': 0.5428571428571429,\n",
       "  'Val_f1Score': 0.2857142857142857,\n",
       "  'Val_precision': 0.16666666666666666,\n",
       "  'Val_recall': 1.0,\n",
       "  'Val_avg_loss': 0.5316233038902283},\n",
       " {'epoch': 2,\n",
       "  'Train_accuracy': 0.8515625,\n",
       "  'Train_mF1Score': 0.5788744588744589,\n",
       "  'Train_f1Score': 0.23999999999999996,\n",
       "  'Train_precision': 0.21428571428571427,\n",
       "  'Train_recall': 0.2727272727272727,\n",
       "  'Train_avg_loss': 0.5979474037885666,\n",
       "  'Val_accuracy': 0.9375,\n",
       "  'Val_mF1Score': 0.4838709677419355,\n",
       "  'Val_f1Score': 0.0,\n",
       "  'Val_precision': 0.0,\n",
       "  'Val_recall': 0.0,\n",
       "  'Val_avg_loss': 0.3841923475265503},\n",
       " {'epoch': 3,\n",
       "  'Train_accuracy': 0.9296875,\n",
       "  'Train_mF1Score': 0.6813278008298754,\n",
       "  'Train_f1Score': 0.39999999999999997,\n",
       "  'Train_precision': 0.75,\n",
       "  'Train_recall': 0.2727272727272727,\n",
       "  'Train_avg_loss': 0.5398473590612411,\n",
       "  'Val_accuracy': 0.9375,\n",
       "  'Val_mF1Score': 0.4838709677419355,\n",
       "  'Val_f1Score': 0.0,\n",
       "  'Val_precision': 0.0,\n",
       "  'Val_recall': 0.0,\n",
       "  'Val_avg_loss': 0.3392186760902405},\n",
       " {'epoch': 4,\n",
       "  'Train_accuracy': 0.9296875,\n",
       "  'Train_mF1Score': 0.6353276353276354,\n",
       "  'Train_f1Score': 0.3076923076923077,\n",
       "  'Train_precision': 1.0,\n",
       "  'Train_recall': 0.18181818181818182,\n",
       "  'Train_avg_loss': 0.5437285602092743,\n",
       "  'Val_accuracy': 0.9375,\n",
       "  'Val_mF1Score': 0.4838709677419355,\n",
       "  'Val_f1Score': 0.0,\n",
       "  'Val_precision': 0.0,\n",
       "  'Val_recall': 0.0,\n",
       "  'Val_avg_loss': 0.33620166778564453}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.run(args,df_train,df_val,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
